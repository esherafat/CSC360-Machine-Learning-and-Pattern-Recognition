{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "Goal: Perform the tranformation on validation and test sets in a right way\n",
    "The following code shows two ways to standardize validation and test sets (here is only shown on a test set).\n",
    "- 1- Run the following code to see the values of X_test_std1 and X_test_std2\n",
    "- 2- Re-apply standardization using StandrdScaler from scikit-learn\n",
    "- 3- Assuming the StandardScaler result is the correct transformation, is the following statement correct? **Yes, because X_test_std2, is same as StandarScaler output.**\n",
    "- \"We should re-use the parameters estimated from the training set to transfrom validation and test sets\" \n",
    "\n",
    "**Note: The standard deviation differs between numpy and pandas. Pandas uses N-1 in the denominator whereas numpy by default does not (sample vs population standard deviation).  We must use numpy std in this assignment since StandardScaler uses numpy std for scaling. Thefore, you should use `df.std(axis=0, ddof=0)` or `df.values.std(axis=0)` to calculate standard deviation for purpose of scaling.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0 -1.224745\n",
      "1  0.000000\n",
      "2  1.224745\n",
      "\n",
      "\n",
      "          0\n",
      "0 -1.837117\n",
      "1 -1.714643\n",
      "2 -1.592168\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.DataFrame([10 ,20, 30])\n",
    "X_test = pd.DataFrame([5,6,7])\n",
    "\n",
    "mu_train, sigma_train = X_train.mean(axis=0), X_train.values.std(axis=0)\n",
    "mu_test, sigma_test = X_test.mean(axis=0), X_test.values.std(axis=0)\n",
    "\n",
    "X_train_std = (X_train - mu_train) / sigma_train\n",
    "X_test_std1 = (X_test - mu_test) / sigma_test\n",
    "X_test_std2 = (X_test - mu_train) / sigma_train\n",
    "print(X_test_std1)\n",
    "print('\\n')\n",
    "print(X_test_std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.83711731]\n",
      " [-1.71464282]\n",
      " [-1.59216833]]\n"
     ]
    }
   ],
   "source": [
    "# Add your code for step 3 here\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "Goal: Try a new data imputation strategy and encourage using scikit-learn documentation\n",
    "- 1- Create a dataframe same as the one in the slide #36 with coding. \n",
    "- 2- Examine its shape and dimensions\n",
    "- 3- Print it to make sure that is what you expect\n",
    "- 4- Use SimpleImputer to impute missing values with constant value equal to -1 \n",
    "- (Hint: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D\n",
      "0   1.0   2.0   3.0  4.0\n",
      "1   5.0   6.0   NaN  8.0\n",
      "2  10.0  11.0  12.0  NaN\n",
      "\n",
      "Shape: (3, 4)\n",
      "\n",
      "\n",
      "array([[ 1.,  2.,  3.,  4.],\n",
      "       [ 5.,  6., -1.,  8.],\n",
      "       [10., 11., 12., -1.]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1, 2, 3\n",
    "tupleList = [(1.0, 2.0, 3.0, 4.0), (5.0, 6.0, np.nan, 8.0), (10.0,11.0,12.0,np.nan)]\n",
    "colNames = ['A', 'B', 'C', 'D']\n",
    "data = pd.DataFrame(tupleList, columns=colNames)\n",
    "print(data)\n",
    "print('\\nShape:', data.shape)\n",
    "print('\\n')\n",
    "\n",
    "# 4\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "const_imp = SimpleImputer(missing_values = np.nan, strategy='constant', fill_value=-1)\n",
    "const_imp.fit(data)\n",
    "print(repr(const_imp.transform(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
